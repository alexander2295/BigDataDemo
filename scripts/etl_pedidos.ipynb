{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60893096",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hola Spark desde VS Code 🚀\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f33dca0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sesión anterior cerrada\n",
      "✅ Spark version: 2.4.5\n",
      "✅ Master URL: spark://spark-master:7077\n",
      "✅ Spark reiniciado con driver JDBC\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Cerrar sesión actual\n",
    "try:\n",
    "    spark.stop()\n",
    "    print(\"✅ Sesión anterior cerrada\")\n",
    "except:\n",
    "    print(\"ℹ️ No había sesión previa\")\n",
    "\n",
    "# Reiniciar con configuración explícita del JAR\n",
    "spark = (SparkSession.builder\n",
    "    .appName(\"Validacion-incremental\")\n",
    "    .master(\"spark://spark-master:7077\")\n",
    "    .config(\"spark.executor.instances\", \"1\")\n",
    "    .config(\"spark.executor.cores\", \"1\")\n",
    "    .config(\"spark.executor.memory\", \"2g\")\n",
    "    .config(\"spark.driver.memory\", \"1g\")\n",
    "    .config(\"spark.jars\", \"/opt/spark/jars/mssql-jdbc-13.2.0.jre8.jar\")\n",
    "    .config(\"spark.driver.extraClassPath\", \"/opt/spark/jars/mssql-jdbc-13.2.0.jre8.jar\")\n",
    "    .config(\"spark.executor.extraClassPath\", \"/opt/spark/jars/mssql-jdbc-13.2.0.jre8.jar\")\n",
    "    .enableHiveSupport()\n",
    "    .getOrCreate())\n",
    "\n",
    "print(\"✅ Spark version:\", spark.version)\n",
    "print(\"✅ Master URL:\", spark.sparkContext.master)\n",
    "print(\"✅ Spark reiniciado con driver JDBC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e7f882c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ¡Conexión JDBC exitosa!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|test_col|\n",
      "+--------+\n",
      "|       1|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Importar configuración\n",
    "import sys\n",
    "sys.path.append(\"/scripts/config\")\n",
    "from db_config import db_config\n",
    "\n",
    "# Probar conexión\n",
    "try:\n",
    "    df_test = (spark.read.format(\"jdbc\")\n",
    "        .option(\"url\", db_config[\"jdbc_url\"])\n",
    "        .option(\"user\", db_config[\"user\"])\n",
    "        .option(\"password\", db_config[\"password\"])\n",
    "        .option(\"driver\", db_config[\"driver\"])\n",
    "        .option(\"query\", \"SELECT 1 AS test_col\")\n",
    "        .load())\n",
    "    \n",
    "    print(\"✅ ¡Conexión JDBC exitosa!\")\n",
    "    df_test.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {str(e)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41d587e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sql_query(query: str):\n",
    "    \"\"\"\n",
    "    Ejecuta un query en SQL Server usando la configuración JDBC del proyecto.\n",
    "    Retorna un DataFrame de Spark.\n",
    "    \"\"\"\n",
    "    return (spark.read.format(\"jdbc\")\n",
    "        .option(\"url\", db_config[\"jdbc_url\"])\n",
    "        .option(\"user\", db_config[\"user\"])\n",
    "        .option(\"password\", db_config[\"password\"])\n",
    "        .option(\"driver\", db_config[\"driver\"])\n",
    "        .option(\"query\", query)   # 👈 usar dbtable, no query\n",
    "        .load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18c35fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pedidos = read_sql_query(\"SELECT  * FROM dbo.Pedidos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5822b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+------+-----------+--------------------+----------+\n",
      "|PedidoID|ClienteID| Monto|FechaPedido|          CreateTime|UpdateTime|\n",
      "+--------+---------+------+-----------+--------------------+----------+\n",
      "|       1|        1|150.50| 2025-09-01|2025-09-14 19:36:...|      null|\n",
      "|       2|        2|200.00| 2025-09-02|2025-09-14 19:36:...|      null|\n",
      "|       3|        3| 50.00| 2025-09-03|2025-09-14 19:36:...|      null|\n",
      "|       4|        4|300.00| 2025-09-04|2025-09-14 19:36:...|      null|\n",
      "|       5|        5|120.00| 2025-09-05|2025-09-14 19:36:...|      null|\n",
      "|       6|        1| 80.00| 2025-09-06|2025-09-14 19:36:...|      null|\n",
      "|       7|        2| 60.00| 2025-09-07|2025-09-14 19:36:...|      null|\n",
      "|       8|        3| 90.00| 2025-09-08|2025-09-14 19:36:...|      null|\n",
      "|       9|        4|110.00| 2025-09-09|2025-09-14 19:36:...|      null|\n",
      "|      10|        5| 75.00| 2025-09-10|2025-09-14 19:36:...|      null|\n",
      "|      11|        7| 95.00| 2025-09-11|2025-09-14 19:36:...|      null|\n",
      "|      12|        8|180.00| 2025-09-12|2025-09-14 19:36:...|      null|\n",
      "|      13|        9|210.00| 2025-09-13|2025-09-14 19:36:...|      null|\n",
      "|      14|       10| 50.00| 2025-09-14|2025-09-14 19:36:...|      null|\n",
      "|      15|       11| 60.00| 2025-09-14|2025-09-14 19:36:...|      null|\n",
      "|      16|       12| 70.00| 2025-09-12|2025-09-14 19:36:...|      null|\n",
      "|      17|       13|200.00| 2025-09-13|2025-09-14 19:36:...|      null|\n",
      "|      18|       14|130.00| 2025-09-10|2025-09-14 19:36:...|      null|\n",
      "|      19|       15| 90.00| 2025-09-11|2025-09-14 19:36:...|      null|\n",
      "|      20|        1|150.00| 2025-09-14|2025-09-14 19:36:...|      null|\n",
      "+--------+---------+------+-----------+--------------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_pedidos.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0588ed03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_pedidos.write.mode(\"overwrite\").parquet(\"hdfs://namenode:8020/bronze/df_pedidos/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b36c45dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+------+-----------+--------------------+----------+\n",
      "|PedidoID|ClienteID| Monto|FechaPedido|          CreateTime|UpdateTime|\n",
      "+--------+---------+------+-----------+--------------------+----------+\n",
      "|       1|        1|150.50| 2025-09-01|2025-09-14 19:36:...|      null|\n",
      "|       2|        2|200.00| 2025-09-02|2025-09-14 19:36:...|      null|\n",
      "|       3|        3| 50.00| 2025-09-03|2025-09-14 19:36:...|      null|\n",
      "|       4|        4|300.00| 2025-09-04|2025-09-14 19:36:...|      null|\n",
      "|       5|        5|120.00| 2025-09-05|2025-09-14 19:36:...|      null|\n",
      "|       6|        1| 80.00| 2025-09-06|2025-09-14 19:36:...|      null|\n",
      "|       7|        2| 60.00| 2025-09-07|2025-09-14 19:36:...|      null|\n",
      "|       8|        3| 90.00| 2025-09-08|2025-09-14 19:36:...|      null|\n",
      "|       9|        4|110.00| 2025-09-09|2025-09-14 19:36:...|      null|\n",
      "|      10|        5| 75.00| 2025-09-10|2025-09-14 19:36:...|      null|\n",
      "|      11|        7| 95.00| 2025-09-11|2025-09-14 19:36:...|      null|\n",
      "|      12|        8|180.00| 2025-09-12|2025-09-14 19:36:...|      null|\n",
      "|      13|        9|210.00| 2025-09-13|2025-09-14 19:36:...|      null|\n",
      "|      14|       10| 50.00| 2025-09-14|2025-09-14 19:36:...|      null|\n",
      "|      15|       11| 60.00| 2025-09-14|2025-09-14 19:36:...|      null|\n",
      "|      16|       12| 70.00| 2025-09-12|2025-09-14 19:36:...|      null|\n",
      "|      17|       13|200.00| 2025-09-13|2025-09-14 19:36:...|      null|\n",
      "|      18|       14|130.00| 2025-09-10|2025-09-14 19:36:...|      null|\n",
      "|      19|       15| 90.00| 2025-09-11|2025-09-14 19:36:...|      null|\n",
      "|      20|        1|150.00| 2025-09-14|2025-09-14 19:36:...|      null|\n",
      "+--------+---------+------+-----------+--------------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_validacion = spark.read.parquet(\"hdfs://namenode:8020/bronze/df_pedidos\")\n",
    "df_validacion.show(30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f814f532",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
